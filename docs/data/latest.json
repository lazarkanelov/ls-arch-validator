{
  "id": "run-20251230-test",
  "status": "completed",
  "started_at": "2025-12-30T10:00:00Z",
  "completed_at": "2025-12-30T10:30:00Z",
  "localstack_version": "latest",
  "statistics": {
    "total": 5,
    "passed": 3,
    "partial": 1,
    "failed": 1,
    "timeout": 0,
    "pass_rate": 60.0
  },
  "template_count": 4,
  "diagram_count": 1,
  "results": [
    {
      "architecture_id": "aws-quickstart-vpc-3tier",
      "source_type": "template",
      "services": ["ec2", "vpc", "rds"],
      "status": "passed",
      "source_info": {
        "source_id": "aws-quickstarts",
        "source_name": "AWS QuickStart Templates",
        "source_type": "template",
        "source_url": "https://github.com/aws-quickstart/quickstart-examples",
        "original_format": "cloudformation"
      },
      "terraform_code": {
        "main_tf": "# AWS VPC 3-Tier Architecture\n\nresource \"aws_vpc\" \"main\" {\n  cidr_block           = \"10.0.0.0/16\"\n  enable_dns_hostnames = true\n  enable_dns_support   = true\n\n  tags = {\n    Name        = \"three-tier-vpc\"\n    Environment = var.environment\n  }\n}\n\nresource \"aws_subnet\" \"public\" {\n  count                   = 2\n  vpc_id                  = aws_vpc.main.id\n  cidr_block              = cidrsubnet(aws_vpc.main.cidr_block, 8, count.index)\n  availability_zone       = data.aws_availability_zones.available.names[count.index]\n  map_public_ip_on_launch = true\n\n  tags = {\n    Name = \"public-subnet-${count.index + 1}\"\n    Tier = \"public\"\n  }\n}\n\nresource \"aws_subnet\" \"private\" {\n  count             = 2\n  vpc_id            = aws_vpc.main.id\n  cidr_block        = cidrsubnet(aws_vpc.main.cidr_block, 8, count.index + 10)\n  availability_zone = data.aws_availability_zones.available.names[count.index]\n\n  tags = {\n    Name = \"private-subnet-${count.index + 1}\"\n    Tier = \"private\"\n  }\n}\n\nresource \"aws_db_subnet_group\" \"main\" {\n  name       = \"main-db-subnet-group\"\n  subnet_ids = aws_subnet.private[*].id\n\n  tags = {\n    Name = \"Main DB Subnet Group\"\n  }\n}\n\nresource \"aws_db_instance\" \"main\" {\n  identifier           = \"app-database\"\n  allocated_storage    = 20\n  storage_type         = \"gp2\"\n  engine               = \"mysql\"\n  engine_version       = \"8.0\"\n  instance_class       = \"db.t3.micro\"\n  db_name              = \"appdb\"\n  username             = var.db_username\n  password             = var.db_password\n  parameter_group_name = \"default.mysql8.0\"\n  skip_final_snapshot  = true\n  db_subnet_group_name = aws_db_subnet_group.main.name\n  vpc_security_group_ids = [aws_security_group.db.id]\n\n  tags = {\n    Name        = \"Application Database\"\n    Environment = var.environment\n  }\n}\n",
        "variables_tf": "variable \"environment\" {\n  type        = string\n  description = \"Deployment environment (dev, staging, prod)\"\n  default     = \"dev\"\n}\n\nvariable \"db_username\" {\n  type        = string\n  description = \"Database administrator username\"\n  sensitive   = true\n}\n\nvariable \"db_password\" {\n  type        = string\n  description = \"Database administrator password\"\n  sensitive   = true\n}\n\nvariable \"allowed_cidr_blocks\" {\n  type        = list(string)\n  description = \"CIDR blocks allowed to access the application\"\n  default     = [\"0.0.0.0/0\"]\n}\n",
        "outputs_tf": "output \"vpc_id\" {\n  value       = aws_vpc.main.id\n  description = \"The ID of the VPC\"\n}\n\noutput \"public_subnet_ids\" {\n  value       = aws_subnet.public[*].id\n  description = \"List of public subnet IDs\"\n}\n\noutput \"private_subnet_ids\" {\n  value       = aws_subnet.private[*].id\n  description = \"List of private subnet IDs\"\n}\n\noutput \"database_endpoint\" {\n  value       = aws_db_instance.main.endpoint\n  description = \"RDS instance endpoint\"\n}\n"
      },
      "generated_app": {
        "content_hash": "saas-backend-v1",
        "source_files": {
          "src/models.py": "\"\"\"Domain models for Multi-Tenant SaaS Backend.\"\"\"\nfrom __future__ import annotations\n\nimport uuid\nfrom dataclasses import dataclass, field\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Optional\n\n\nclass SubscriptionTier(str, Enum):\n    FREE = \"free\"\n    STARTER = \"starter\"\n    PROFESSIONAL = \"professional\"\n    ENTERPRISE = \"enterprise\"\n\n\nclass UserRole(str, Enum):\n    OWNER = \"owner\"\n    ADMIN = \"admin\"\n    MEMBER = \"member\"\n    VIEWER = \"viewer\"\n\n\n@dataclass\nclass Tenant:\n    \"\"\"Represents a tenant organization in the SaaS platform.\"\"\"\n    tenant_id: str = field(default_factory=lambda: str(uuid.uuid4()))\n    name: str = \"\"\n    subdomain: str = \"\"\n    subscription_tier: SubscriptionTier = SubscriptionTier.FREE\n    created_at: datetime = field(default_factory=datetime.utcnow)\n    is_active: bool = True\n    settings: dict = field(default_factory=dict)\n    \n    def to_dict(self) -> dict:\n        return {\n            \"tenant_id\": self.tenant_id,\n            \"name\": self.name,\n            \"subdomain\": self.subdomain,\n            \"subscription_tier\": self.subscription_tier.value,\n            \"created_at\": self.created_at.isoformat(),\n            \"is_active\": self.is_active,\n            \"settings\": self.settings,\n        }\n\n\n@dataclass\nclass User:\n    \"\"\"Represents a user within a tenant.\"\"\"\n    user_id: str = field(default_factory=lambda: str(uuid.uuid4()))\n    tenant_id: str = \"\"\n    email: str = \"\"\n    password_hash: str = \"\"\n    full_name: str = \"\"\n    role: UserRole = UserRole.MEMBER\n    created_at: datetime = field(default_factory=datetime.utcnow)\n    last_login: Optional[datetime] = None\n    is_active: bool = True\n    mfa_enabled: bool = False\n    \n    def has_permission(self, required_role: UserRole) -> bool:\n        \"\"\"Check if user has at least the required role level.\"\"\"\n        role_hierarchy = [UserRole.VIEWER, UserRole.MEMBER, UserRole.ADMIN, UserRole.OWNER]\n        return role_hierarchy.index(self.role) >= role_hierarchy.index(required_role)\n\n\n@dataclass\nclass Session:\n    \"\"\"User session with JWT token management.\"\"\"\n    session_id: str = field(default_factory=lambda: str(uuid.uuid4()))\n    user_id: str = \"\"\n    tenant_id: str = \"\"\n    token: str = \"\"\n    created_at: datetime = field(default_factory=datetime.utcnow)\n    expires_at: datetime = None\n    ip_address: str = \"\"\n    user_agent: str = \"\"\n    is_revoked: bool = False\n\n\n@dataclass\nclass AuditLog:\n    \"\"\"Audit log entry for compliance tracking.\"\"\"\n    log_id: str = field(default_factory=lambda: str(uuid.uuid4()))\n    tenant_id: str = \"\"\n    user_id: str = \"\"\n    action: str = \"\"\n    resource_type: str = \"\"\n    resource_id: str = \"\"\n    old_value: Optional[dict] = None\n    new_value: Optional[dict] = None\n    timestamp: datetime = field(default_factory=datetime.utcnow)\n    ip_address: str = \"\"\n    correlation_id: str = \"\"\n",
          "src/repositories.py": "\"\"\"Data access layer with tenant isolation.\"\"\"\nfrom __future__ import annotations\n\nimport logging\nfrom contextlib import contextmanager\nfrom typing import Generator, Optional\n\nimport mysql.connector\nfrom mysql.connector import pooling\n\nfrom src.config import settings\nfrom src.models import AuditLog, Session, Tenant, User\n\nlogger = logging.getLogger(__name__)\n\n\nclass DatabasePool:\n    \"\"\"Connection pool manager for RDS MySQL.\"\"\"\n    \n    _pool: Optional[pooling.MySQLConnectionPool] = None\n    \n    @classmethod\n    def get_pool(cls) -> pooling.MySQLConnectionPool:\n        if cls._pool is None:\n            cls._pool = pooling.MySQLConnectionPool(\n                pool_name=\"saas_pool\",\n                pool_size=5,\n                host=settings.db_host,\n                port=settings.db_port,\n                user=settings.db_username,\n                password=settings.db_password,\n                database=settings.db_name,\n            )\n        return cls._pool\n    \n    @classmethod\n    @contextmanager\n    def get_connection(cls) -> Generator:\n        conn = cls.get_pool().get_connection()\n        try:\n            yield conn\n        finally:\n            conn.close()\n\n\nclass TenantRepository:\n    \"\"\"Repository for tenant operations with row-level security.\"\"\"\n    \n    def create(self, tenant: Tenant) -> Tenant:\n        \"\"\"Create a new tenant with isolated schema.\"\"\"\n        with DatabasePool.get_connection() as conn:\n            cursor = conn.cursor(dictionary=True)\n            try:\n                cursor.execute(\n                    \"\"\"INSERT INTO tenants \n                    (tenant_id, name, subdomain, subscription_tier, created_at, is_active, settings)\n                    VALUES (%s, %s, %s, %s, %s, %s, %s)\"\"\",\n                    (tenant.tenant_id, tenant.name, tenant.subdomain,\n                     tenant.subscription_tier.value, tenant.created_at,\n                     tenant.is_active, str(tenant.settings))\n                )\n                conn.commit()\n                logger.info(\"tenant_created\", extra={\"tenant_id\": tenant.tenant_id})\n                return tenant\n            except mysql.connector.IntegrityError as e:\n                conn.rollback()\n                raise DuplicateTenantError(f\"Tenant {tenant.subdomain} already exists\") from e\n    \n    def get_by_id(self, tenant_id: str) -> Optional[Tenant]:\n        \"\"\"Retrieve tenant by ID.\"\"\"\n        with DatabasePool.get_connection() as conn:\n            cursor = conn.cursor(dictionary=True)\n            cursor.execute(\n                \"SELECT * FROM tenants WHERE tenant_id = %s AND is_active = TRUE\",\n                (tenant_id,)\n            )\n            row = cursor.fetchone()\n            return self._row_to_tenant(row) if row else None\n    \n    def get_by_subdomain(self, subdomain: str) -> Optional[Tenant]:\n        \"\"\"Retrieve tenant by subdomain for routing.\"\"\"\n        with DatabasePool.get_connection() as conn:\n            cursor = conn.cursor(dictionary=True)\n            cursor.execute(\n                \"SELECT * FROM tenants WHERE subdomain = %s AND is_active = TRUE\",\n                (subdomain,)\n            )\n            row = cursor.fetchone()\n            return self._row_to_tenant(row) if row else None\n    \n    def _row_to_tenant(self, row: dict) -> Tenant:\n        return Tenant(\n            tenant_id=row[\"tenant_id\"],\n            name=row[\"name\"],\n            subdomain=row[\"subdomain\"],\n            subscription_tier=row[\"subscription_tier\"],\n            created_at=row[\"created_at\"],\n            is_active=row[\"is_active\"],\n        )\n\n\nclass UserRepository:\n    \"\"\"Repository for user operations with tenant isolation.\"\"\"\n    \n    def create(self, user: User) -> User:\n        \"\"\"Create a new user within a tenant.\"\"\"\n        with DatabasePool.get_connection() as conn:\n            cursor = conn.cursor()\n            cursor.execute(\n                \"\"\"INSERT INTO users \n                (user_id, tenant_id, email, password_hash, full_name, role, created_at)\n                VALUES (%s, %s, %s, %s, %s, %s, %s)\"\"\",\n                (user.user_id, user.tenant_id, user.email, user.password_hash,\n                 user.full_name, user.role.value, user.created_at)\n            )\n            conn.commit()\n            return user\n    \n    def get_by_email(self, tenant_id: str, email: str) -> Optional[User]:\n        \"\"\"Get user by email within tenant scope (row-level security).\"\"\"\n        with DatabasePool.get_connection() as conn:\n            cursor = conn.cursor(dictionary=True)\n            cursor.execute(\n                \"\"\"SELECT * FROM users \n                WHERE tenant_id = %s AND email = %s AND is_active = TRUE\"\"\",\n                (tenant_id, email)\n            )\n            row = cursor.fetchone()\n            return self._row_to_user(row) if row else None\n    \n    def update_last_login(self, user_id: str) -> None:\n        \"\"\"Update user's last login timestamp.\"\"\"\n        with DatabasePool.get_connection() as conn:\n            cursor = conn.cursor()\n            cursor.execute(\n                \"UPDATE users SET last_login = NOW() WHERE user_id = %s\",\n                (user_id,)\n            )\n            conn.commit()\n\n\nclass AuditLogRepository:\n    \"\"\"Repository for compliance audit logs.\"\"\"\n    \n    def log(self, entry: AuditLog) -> None:\n        \"\"\"Write an audit log entry (append-only).\"\"\"\n        with DatabasePool.get_connection() as conn:\n            cursor = conn.cursor()\n            cursor.execute(\n                \"\"\"INSERT INTO audit_logs\n                (log_id, tenant_id, user_id, action, resource_type, resource_id,\n                 old_value, new_value, timestamp, ip_address, correlation_id)\n                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\"\"\",\n                (entry.log_id, entry.tenant_id, entry.user_id, entry.action,\n                 entry.resource_type, entry.resource_id, str(entry.old_value),\n                 str(entry.new_value), entry.timestamp, entry.ip_address,\n                 entry.correlation_id)\n            )\n            conn.commit()\n    \n    def query_by_tenant(\n        self, tenant_id: str, start_date: str, end_date: str, limit: int = 100\n    ) -> list[AuditLog]:\n        \"\"\"Query audit logs for a tenant within date range.\"\"\"\n        with DatabasePool.get_connection() as conn:\n            cursor = conn.cursor(dictionary=True)\n            cursor.execute(\n                \"\"\"SELECT * FROM audit_logs \n                WHERE tenant_id = %s AND timestamp BETWEEN %s AND %s\n                ORDER BY timestamp DESC LIMIT %s\"\"\",\n                (tenant_id, start_date, end_date, limit)\n            )\n            return [self._row_to_log(row) for row in cursor.fetchall()]\n\n\nclass DuplicateTenantError(Exception):\n    \"\"\"Raised when attempting to create a duplicate tenant.\"\"\"\n    pass\n",
          "src/services.py": "\"\"\"Business logic layer for SaaS operations.\"\"\"\nfrom __future__ import annotations\n\nimport hashlib\nimport hmac\nimport logging\nimport secrets\nfrom datetime import datetime, timedelta\nfrom typing import Optional\n\nimport jwt\n\nfrom src.config import settings\nfrom src.models import AuditLog, Session, SubscriptionTier, Tenant, User, UserRole\nfrom src.repositories import (\n    AuditLogRepository,\n    TenantRepository,\n    UserRepository,\n)\n\nlogger = logging.getLogger(__name__)\n\n\nclass AuthenticationService:\n    \"\"\"Handles user authentication with JWT tokens.\"\"\"\n    \n    def __init__(self):\n        self.user_repo = UserRepository()\n        self.audit_repo = AuditLogRepository()\n    \n    def hash_password(self, password: str) -> str:\n        \"\"\"Hash password using PBKDF2 with salt.\"\"\"\n        salt = secrets.token_hex(16)\n        hash_obj = hashlib.pbkdf2_hmac(\n            \"sha256\", password.encode(), salt.encode(), 100000\n        )\n        return f\"{salt}${hash_obj.hex()}\"\n    \n    def verify_password(self, password: str, password_hash: str) -> bool:\n        \"\"\"Verify password against stored hash.\"\"\"\n        try:\n            salt, stored_hash = password_hash.split(\"$\")\n            hash_obj = hashlib.pbkdf2_hmac(\n                \"sha256\", password.encode(), salt.encode(), 100000\n            )\n            return hmac.compare_digest(hash_obj.hex(), stored_hash)\n        except ValueError:\n            return False\n    \n    def authenticate(\n        self, tenant_id: str, email: str, password: str, ip_address: str\n    ) -> Optional[Session]:\n        \"\"\"Authenticate user and create session.\"\"\"\n        user = self.user_repo.get_by_email(tenant_id, email)\n        \n        if not user or not self.verify_password(password, user.password_hash):\n            self._log_failed_login(tenant_id, email, ip_address)\n            return None\n        \n        session = self._create_session(user, ip_address)\n        self.user_repo.update_last_login(user.user_id)\n        \n        self.audit_repo.log(AuditLog(\n            tenant_id=tenant_id,\n            user_id=user.user_id,\n            action=\"user.login\",\n            resource_type=\"session\",\n            resource_id=session.session_id,\n            ip_address=ip_address,\n        ))\n        \n        logger.info(\"user_authenticated\", extra={\n            \"user_id\": user.user_id,\n            \"tenant_id\": tenant_id,\n        })\n        return session\n    \n    def _create_session(self, user: User, ip_address: str) -> Session:\n        \"\"\"Create JWT session token.\"\"\"\n        expires_at = datetime.utcnow() + timedelta(hours=settings.session_ttl_hours)\n        \n        payload = {\n            \"sub\": user.user_id,\n            \"tenant_id\": user.tenant_id,\n            \"role\": user.role.value,\n            \"exp\": expires_at,\n            \"iat\": datetime.utcnow(),\n        }\n        token = jwt.encode(payload, settings.jwt_secret, algorithm=\"HS256\")\n        \n        return Session(\n            user_id=user.user_id,\n            tenant_id=user.tenant_id,\n            token=token,\n            expires_at=expires_at,\n            ip_address=ip_address,\n        )\n    \n    def validate_token(self, token: str) -> Optional[dict]:\n        \"\"\"Validate JWT token and return payload.\"\"\"\n        try:\n            payload = jwt.decode(token, settings.jwt_secret, algorithms=[\"HS256\"])\n            return payload\n        except jwt.ExpiredSignatureError:\n            logger.warning(\"token_expired\")\n            return None\n        except jwt.InvalidTokenError:\n            logger.warning(\"invalid_token\")\n            return None\n\n\nclass TenantService:\n    \"\"\"Manages tenant lifecycle and subscriptions.\"\"\"\n    \n    def __init__(self):\n        self.tenant_repo = TenantRepository()\n        self.user_repo = UserRepository()\n        self.auth_service = AuthenticationService()\n        self.audit_repo = AuditLogRepository()\n    \n    def create_tenant(\n        self, name: str, subdomain: str, owner_email: str, owner_password: str\n    ) -> tuple[Tenant, User]:\n        \"\"\"Create new tenant with owner user (transactional).\"\"\"\n        # Validate subdomain format\n        if not self._is_valid_subdomain(subdomain):\n            raise InvalidSubdomainError(f\"Invalid subdomain: {subdomain}\")\n        \n        # Create tenant\n        tenant = Tenant(\n            name=name,\n            subdomain=subdomain,\n            subscription_tier=SubscriptionTier.FREE,\n        )\n        tenant = self.tenant_repo.create(tenant)\n        \n        # Create owner user\n        owner = User(\n            tenant_id=tenant.tenant_id,\n            email=owner_email,\n            password_hash=self.auth_service.hash_password(owner_password),\n            full_name=name,\n            role=UserRole.OWNER,\n        )\n        owner = self.user_repo.create(owner)\n        \n        self.audit_repo.log(AuditLog(\n            tenant_id=tenant.tenant_id,\n            user_id=owner.user_id,\n            action=\"tenant.created\",\n            resource_type=\"tenant\",\n            resource_id=tenant.tenant_id,\n            new_value=tenant.to_dict(),\n        ))\n        \n        logger.info(\"tenant_created\", extra={\n            \"tenant_id\": tenant.tenant_id,\n            \"subdomain\": subdomain,\n        })\n        return tenant, owner\n    \n    def upgrade_subscription(\n        self, tenant_id: str, new_tier: SubscriptionTier, user_id: str\n    ) -> Tenant:\n        \"\"\"Upgrade tenant subscription with billing event.\"\"\"\n        tenant = self.tenant_repo.get_by_id(tenant_id)\n        if not tenant:\n            raise TenantNotFoundError(f\"Tenant {tenant_id} not found\")\n        \n        old_tier = tenant.subscription_tier\n        tenant.subscription_tier = new_tier\n        \n        # In real implementation: trigger billing, provision resources\n        self.audit_repo.log(AuditLog(\n            tenant_id=tenant_id,\n            user_id=user_id,\n            action=\"subscription.upgraded\",\n            resource_type=\"tenant\",\n            resource_id=tenant_id,\n            old_value={\"tier\": old_tier.value},\n            new_value={\"tier\": new_tier.value},\n        ))\n        \n        return tenant\n    \n    def _is_valid_subdomain(self, subdomain: str) -> bool:\n        \"\"\"Validate subdomain format.\"\"\"\n        import re\n        pattern = r\"^[a-z][a-z0-9-]{2,30}[a-z0-9]$\"\n        reserved = [\"www\", \"api\", \"admin\", \"app\", \"mail\"]\n        return bool(re.match(pattern, subdomain)) and subdomain not in reserved\n\n\nclass TenantNotFoundError(Exception):\n    pass\n\n\nclass InvalidSubdomainError(Exception):\n    pass\n",
          "src/handlers.py": "\"\"\"API request handlers for SaaS endpoints.\"\"\"\nfrom __future__ import annotations\n\nimport json\nimport logging\nimport uuid\nfrom functools import wraps\nfrom typing import Any, Callable\n\nfrom src.models import SubscriptionTier\nfrom src.services import (\n    AuthenticationService,\n    TenantService,\n    TenantNotFoundError,\n    InvalidSubdomainError,\n)\n\nlogger = logging.getLogger(__name__)\n\n\ndef with_correlation_id(handler: Callable) -> Callable:\n    \"\"\"Decorator to add correlation ID for distributed tracing.\"\"\"\n    @wraps(handler)\n    def wrapper(event: dict, context: Any) -> dict:\n        correlation_id = event.get(\"headers\", {}).get(\n            \"X-Correlation-ID\", str(uuid.uuid4())\n        )\n        logger.info(\"request_started\", extra={\n            \"correlation_id\": correlation_id,\n            \"path\": event.get(\"path\"),\n            \"method\": event.get(\"httpMethod\"),\n        })\n        \n        try:\n            response = handler(event, context, correlation_id)\n            response[\"headers\"] = response.get(\"headers\", {})\n            response[\"headers\"][\"X-Correlation-ID\"] = correlation_id\n            return response\n        except Exception as e:\n            logger.exception(\"request_failed\", extra={\"correlation_id\": correlation_id})\n            raise\n    return wrapper\n\n\ndef require_auth(handler: Callable) -> Callable:\n    \"\"\"Decorator to require valid JWT authentication.\"\"\"\n    @wraps(handler)\n    def wrapper(event: dict, context: Any, correlation_id: str) -> dict:\n        auth_header = event.get(\"headers\", {}).get(\"Authorization\", \"\")\n        \n        if not auth_header.startswith(\"Bearer \"):\n            return api_response(401, {\"error\": \"Missing authentication token\"})\n        \n        token = auth_header[7:]\n        auth_service = AuthenticationService()\n        payload = auth_service.validate_token(token)\n        \n        if not payload:\n            return api_response(401, {\"error\": \"Invalid or expired token\"})\n        \n        event[\"auth\"] = payload\n        return handler(event, context, correlation_id)\n    return wrapper\n\n\ndef api_response(status_code: int, body: dict) -> dict:\n    \"\"\"Create standardized API response.\"\"\"\n    return {\n        \"statusCode\": status_code,\n        \"headers\": {\n            \"Content-Type\": \"application/json\",\n            \"Access-Control-Allow-Origin\": \"*\",\n        },\n        \"body\": json.dumps(body),\n    }\n\n\n@with_correlation_id\ndef handle_create_tenant(event: dict, context: Any, correlation_id: str) -> dict:\n    \"\"\"POST /tenants - Create new tenant with owner.\"\"\"\n    try:\n        body = json.loads(event.get(\"body\", \"{}\"))\n        \n        # Validate required fields\n        required = [\"name\", \"subdomain\", \"owner_email\", \"owner_password\"]\n        missing = [f for f in required if f not in body]\n        if missing:\n            return api_response(400, {\n                \"error\": \"Missing required fields\",\n                \"fields\": missing,\n            })\n        \n        tenant_service = TenantService()\n        tenant, owner = tenant_service.create_tenant(\n            name=body[\"name\"],\n            subdomain=body[\"subdomain\"],\n            owner_email=body[\"owner_email\"],\n            owner_password=body[\"owner_password\"],\n        )\n        \n        return api_response(201, {\n            \"tenant_id\": tenant.tenant_id,\n            \"subdomain\": tenant.subdomain,\n            \"owner_id\": owner.user_id,\n            \"message\": \"Tenant created successfully\",\n        })\n        \n    except InvalidSubdomainError as e:\n        return api_response(400, {\"error\": str(e)})\n    except Exception as e:\n        logger.exception(\"create_tenant_failed\")\n        return api_response(500, {\"error\": \"Internal server error\"})\n\n\n@with_correlation_id\ndef handle_login(event: dict, context: Any, correlation_id: str) -> dict:\n    \"\"\"POST /auth/login - Authenticate user.\"\"\"\n    try:\n        body = json.loads(event.get(\"body\", \"{}\"))\n        tenant_subdomain = event.get(\"pathParameters\", {}).get(\"subdomain\")\n        \n        # Resolve tenant from subdomain\n        tenant_service = TenantService()\n        tenant = tenant_service.tenant_repo.get_by_subdomain(tenant_subdomain)\n        \n        if not tenant:\n            return api_response(404, {\"error\": \"Tenant not found\"})\n        \n        # Authenticate user\n        auth_service = AuthenticationService()\n        ip_address = event.get(\"requestContext\", {}).get(\"identity\", {}).get(\n            \"sourceIp\", \"unknown\"\n        )\n        \n        session = auth_service.authenticate(\n            tenant_id=tenant.tenant_id,\n            email=body.get(\"email\"),\n            password=body.get(\"password\"),\n            ip_address=ip_address,\n        )\n        \n        if not session:\n            return api_response(401, {\"error\": \"Invalid credentials\"})\n        \n        return api_response(200, {\n            \"token\": session.token,\n            \"expires_at\": session.expires_at.isoformat(),\n            \"user_id\": session.user_id,\n        })\n        \n    except Exception as e:\n        logger.exception(\"login_failed\")\n        return api_response(500, {\"error\": \"Internal server error\"})\n\n\n@with_correlation_id\n@require_auth\ndef handle_upgrade_subscription(\n    event: dict, context: Any, correlation_id: str\n) -> dict:\n    \"\"\"POST /tenants/{id}/subscription - Upgrade subscription.\"\"\"\n    try:\n        tenant_id = event.get(\"pathParameters\", {}).get(\"tenant_id\")\n        auth = event.get(\"auth\", {})\n        \n        # Verify user belongs to tenant and has permission\n        if auth.get(\"tenant_id\") != tenant_id or auth.get(\"role\") not in [\"owner\", \"admin\"]:\n            return api_response(403, {\"error\": \"Insufficient permissions\"})\n        \n        body = json.loads(event.get(\"body\", \"{}\"))\n        new_tier = SubscriptionTier(body.get(\"tier\"))\n        \n        tenant_service = TenantService()\n        tenant = tenant_service.upgrade_subscription(\n            tenant_id=tenant_id,\n            new_tier=new_tier,\n            user_id=auth.get(\"sub\"),\n        )\n        \n        return api_response(200, {\n            \"tenant_id\": tenant.tenant_id,\n            \"subscription_tier\": tenant.subscription_tier.value,\n            \"message\": \"Subscription upgraded successfully\",\n        })\n        \n    except TenantNotFoundError:\n        return api_response(404, {\"error\": \"Tenant not found\"})\n    except ValueError:\n        return api_response(400, {\"error\": \"Invalid subscription tier\"})\n",
          "src/config.py": "\"\"\"Configuration management for SaaS backend.\"\"\"\nfrom __future__ import annotations\n\nimport os\nfrom dataclasses import dataclass\nfrom functools import lru_cache\n\n\n@dataclass\nclass Settings:\n    \"\"\"Application settings with environment-based configuration.\"\"\"\n    \n    # Environment\n    environment: str = os.getenv(\"ENVIRONMENT\", \"development\")\n    debug: bool = os.getenv(\"DEBUG\", \"false\").lower() == \"true\"\n    \n    # Database (RDS MySQL)\n    db_host: str = os.getenv(\"DB_HOST\", \"localhost\")\n    db_port: int = int(os.getenv(\"DB_PORT\", \"3306\"))\n    db_name: str = os.getenv(\"DB_NAME\", \"saas_db\")\n    db_username: str = os.getenv(\"DB_USERNAME\", \"admin\")\n    db_password: str = os.getenv(\"DB_PASSWORD\", \"\")\n    \n    # AWS / LocalStack\n    aws_endpoint_url: str = os.getenv(\"AWS_ENDPOINT_URL\", \"http://localhost:4566\")\n    aws_region: str = os.getenv(\"AWS_REGION\", \"us-east-1\")\n    use_localstack: bool = os.getenv(\"USE_LOCALSTACK\", \"true\").lower() == \"true\"\n    \n    # Authentication\n    jwt_secret: str = os.getenv(\"JWT_SECRET\", \"dev-secret-change-in-production\")\n    session_ttl_hours: int = int(os.getenv(\"SESSION_TTL_HOURS\", \"24\"))\n    \n    # Feature flags\n    enable_audit_logging: bool = os.getenv(\"ENABLE_AUDIT_LOGGING\", \"true\").lower() == \"true\"\n    enable_mfa: bool = os.getenv(\"ENABLE_MFA\", \"false\").lower() == \"true\"\n\n\n@lru_cache(maxsize=1)\ndef get_settings() -> Settings:\n    \"\"\"Get cached settings instance.\"\"\"\n    return Settings()\n\n\nsettings = get_settings()\n",
          "src/__init__.py": "\"\"\"Multi-Tenant SaaS Backend Package.\"\"\"\nimport logging\nimport sys\n\n# Configure structured logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n    handlers=[logging.StreamHandler(sys.stdout)],\n)\n\n__version__ = \"1.0.0\"\n"
        },
        "test_files": {
          "tests/conftest.py": "\"\"\"Pytest fixtures for SaaS backend tests.\"\"\"\nimport os\nimport pytest\nimport mysql.connector\nfrom faker import Faker\n\nfrom src.config import Settings\nfrom src.models import Tenant, User, UserRole, SubscriptionTier\nfrom src.services import AuthenticationService\n\nfake = Faker()\n\n\n@pytest.fixture(scope=\"session\")\ndef localstack_settings():\n    \"\"\"Settings configured for LocalStack.\"\"\"\n    os.environ[\"AWS_ENDPOINT_URL\"] = \"http://localhost:4566\"\n    os.environ[\"USE_LOCALSTACK\"] = \"true\"\n    os.environ[\"DB_HOST\"] = \"localhost\"\n    return Settings()\n\n\n@pytest.fixture\ndef db_connection(localstack_settings):\n    \"\"\"Database connection for test isolation.\"\"\"\n    conn = mysql.connector.connect(\n        host=localstack_settings.db_host,\n        port=localstack_settings.db_port,\n        user=localstack_settings.db_username,\n        password=localstack_settings.db_password,\n        database=localstack_settings.db_name,\n    )\n    yield conn\n    conn.rollback()\n    conn.close()\n\n\n@pytest.fixture\ndef sample_tenant():\n    \"\"\"Generate a sample tenant for testing.\"\"\"\n    return Tenant(\n        name=fake.company(),\n        subdomain=fake.slug()[:20],\n        subscription_tier=SubscriptionTier.STARTER,\n    )\n\n\n@pytest.fixture\ndef sample_user(sample_tenant):\n    \"\"\"Generate a sample user within a tenant.\"\"\"\n    auth = AuthenticationService()\n    return User(\n        tenant_id=sample_tenant.tenant_id,\n        email=fake.email(),\n        password_hash=auth.hash_password(\"SecureP@ss123\"),\n        full_name=fake.name(),\n        role=UserRole.ADMIN,\n    )\n\n\n@pytest.fixture\ndef auth_token(sample_tenant, sample_user):\n    \"\"\"Generate valid JWT token for authenticated tests.\"\"\"\n    auth = AuthenticationService()\n    session = auth._create_session(sample_user, \"127.0.0.1\")\n    return session.token\n",
          "tests/test_services.py": "\"\"\"Tests for business logic services.\"\"\"\nimport pytest\nfrom datetime import datetime, timedelta\n\nfrom src.models import SubscriptionTier, UserRole\nfrom src.services import (\n    AuthenticationService,\n    TenantService,\n    InvalidSubdomainError,\n)\n\n\nclass TestAuthenticationService:\n    \"\"\"Test authentication workflows.\"\"\"\n    \n    def test_password_hashing_produces_unique_hashes(self):\n        \"\"\"Each hash should be unique due to salt.\"\"\"\n        auth = AuthenticationService()\n        hash1 = auth.hash_password(\"password123\")\n        hash2 = auth.hash_password(\"password123\")\n        assert hash1 != hash2\n    \n    def test_password_verification_succeeds(self):\n        \"\"\"Correct password should verify successfully.\"\"\"\n        auth = AuthenticationService()\n        password = \"MySecureP@ssw0rd!\"\n        hashed = auth.hash_password(password)\n        assert auth.verify_password(password, hashed) is True\n    \n    def test_password_verification_fails_wrong_password(self):\n        \"\"\"Wrong password should fail verification.\"\"\"\n        auth = AuthenticationService()\n        hashed = auth.hash_password(\"correct\")\n        assert auth.verify_password(\"wrong\", hashed) is False\n    \n    def test_jwt_token_contains_required_claims(self, sample_user):\n        \"\"\"JWT should contain user_id, tenant_id, role, exp.\"\"\"\n        auth = AuthenticationService()\n        session = auth._create_session(sample_user, \"10.0.0.1\")\n        \n        payload = auth.validate_token(session.token)\n        assert payload[\"sub\"] == sample_user.user_id\n        assert payload[\"tenant_id\"] == sample_user.tenant_id\n        assert payload[\"role\"] == sample_user.role.value\n        assert \"exp\" in payload\n    \n    def test_expired_token_returns_none(self, sample_user):\n        \"\"\"Expired tokens should fail validation.\"\"\"\n        auth = AuthenticationService()\n        # Create expired session manually\n        import jwt\n        from src.config import settings\n        \n        payload = {\n            \"sub\": sample_user.user_id,\n            \"exp\": datetime.utcnow() - timedelta(hours=1),\n        }\n        token = jwt.encode(payload, settings.jwt_secret, algorithm=\"HS256\")\n        \n        assert auth.validate_token(token) is None\n\n\nclass TestTenantService:\n    \"\"\"Test tenant management workflows.\"\"\"\n    \n    def test_create_tenant_returns_tenant_and_owner(self):\n        \"\"\"Creating tenant should return both tenant and owner user.\"\"\"\n        service = TenantService()\n        tenant, owner = service.create_tenant(\n            name=\"Acme Corp\",\n            subdomain=\"acme-corp\",\n            owner_email=\"owner@acme.com\",\n            owner_password=\"SecureP@ss123\",\n        )\n        \n        assert tenant.name == \"Acme Corp\"\n        assert tenant.subdomain == \"acme-corp\"\n        assert owner.role == UserRole.OWNER\n        assert owner.tenant_id == tenant.tenant_id\n    \n    def test_subdomain_validation_rejects_reserved_words(self):\n        \"\"\"Reserved subdomains like 'api' should be rejected.\"\"\"\n        service = TenantService()\n        \n        with pytest.raises(InvalidSubdomainError):\n            service.create_tenant(\n                name=\"API Company\",\n                subdomain=\"api\",\n                owner_email=\"owner@api.com\",\n                owner_password=\"password\",\n            )\n    \n    def test_subdomain_validation_rejects_invalid_format(self):\n        \"\"\"Invalid subdomain formats should be rejected.\"\"\"\n        service = TenantService()\n        invalid_subdomains = [\"ab\", \"-invalid\", \"has spaces\", \"UPPERCASE\"]\n        \n        for subdomain in invalid_subdomains:\n            with pytest.raises(InvalidSubdomainError):\n                service.create_tenant(\n                    name=\"Test\",\n                    subdomain=subdomain,\n                    owner_email=\"test@test.com\",\n                    owner_password=\"password\",\n                )\n    \n    def test_subscription_upgrade_creates_audit_log(self, sample_tenant):\n        \"\"\"Upgrading subscription should create audit entry.\"\"\"\n        service = TenantService()\n        # Setup: create tenant first\n        service.tenant_repo.create(sample_tenant)\n        \n        updated = service.upgrade_subscription(\n            tenant_id=sample_tenant.tenant_id,\n            new_tier=SubscriptionTier.PROFESSIONAL,\n            user_id=\"user-123\",\n        )\n        \n        assert updated.subscription_tier == SubscriptionTier.PROFESSIONAL\n",
          "tests/test_integration.py": "\"\"\"End-to-end integration tests.\"\"\"\nimport json\nimport pytest\n\nfrom src.handlers import (\n    handle_create_tenant,\n    handle_login,\n    handle_upgrade_subscription,\n)\nfrom src.models import SubscriptionTier\n\n\nclass TestTenantOnboarding:\n    \"\"\"Test complete tenant onboarding flow.\"\"\"\n    \n    def test_full_tenant_signup_flow(self):\n        \"\"\"Test: signup -> login -> upgrade subscription.\"\"\"\n        # Step 1: Create tenant\n        create_event = {\n            \"body\": json.dumps({\n                \"name\": \"Integration Test Corp\",\n                \"subdomain\": \"integration-test\",\n                \"owner_email\": \"owner@integration.test\",\n                \"owner_password\": \"TestP@ssw0rd!\",\n            }),\n            \"headers\": {},\n        }\n        \n        response = handle_create_tenant(create_event, None)\n        assert response[\"statusCode\"] == 201\n        \n        body = json.loads(response[\"body\"])\n        tenant_id = body[\"tenant_id\"]\n        \n        # Step 2: Login as owner\n        login_event = {\n            \"body\": json.dumps({\n                \"email\": \"owner@integration.test\",\n                \"password\": \"TestP@ssw0rd!\",\n            }),\n            \"pathParameters\": {\"subdomain\": \"integration-test\"},\n            \"headers\": {},\n            \"requestContext\": {\"identity\": {\"sourceIp\": \"127.0.0.1\"}},\n        }\n        \n        response = handle_login(login_event, None)\n        assert response[\"statusCode\"] == 200\n        \n        token = json.loads(response[\"body\"])[\"token\"]\n        \n        # Step 3: Upgrade subscription\n        upgrade_event = {\n            \"body\": json.dumps({\"tier\": \"professional\"}),\n            \"pathParameters\": {\"tenant_id\": tenant_id},\n            \"headers\": {\"Authorization\": f\"Bearer {token}\"},\n        }\n        \n        response = handle_upgrade_subscription(upgrade_event, None)\n        assert response[\"statusCode\"] == 200\n        \n        body = json.loads(response[\"body\"])\n        assert body[\"subscription_tier\"] == \"professional\"\n    \n    def test_login_fails_with_wrong_credentials(self):\n        \"\"\"Login with wrong password should return 401.\"\"\"\n        login_event = {\n            \"body\": json.dumps({\n                \"email\": \"owner@integration.test\",\n                \"password\": \"WrongPassword\",\n            }),\n            \"pathParameters\": {\"subdomain\": \"integration-test\"},\n            \"headers\": {},\n            \"requestContext\": {\"identity\": {\"sourceIp\": \"127.0.0.1\"}},\n        }\n        \n        response = handle_login(login_event, None)\n        assert response[\"statusCode\"] == 401\n    \n    def test_unauthorized_upgrade_fails(self):\n        \"\"\"Non-owner/admin users cannot upgrade subscription.\"\"\"\n        # Simulate request from member user\n        upgrade_event = {\n            \"body\": json.dumps({\"tier\": \"enterprise\"}),\n            \"pathParameters\": {\"tenant_id\": \"tenant-123\"},\n            \"headers\": {\"Authorization\": \"Bearer invalid-token\"},\n        }\n        \n        response = handle_upgrade_subscription(upgrade_event, None)\n        assert response[\"statusCode\"] == 401\n"
        },
        "requirements": ["boto3>=1.28.0", "pydantic>=2.0.0", "PyJWT>=2.8.0", "mysql-connector-python>=8.0.0", "pytest>=7.0.0", "faker>=18.0.0"],
        "source_file_count": 6,
        "test_file_count": 3,
        "requirements_count": 6
      }
    },
    {
      "architecture_id": "terraform-aws-lambda-api",
      "source_type": "template",
      "services": ["lambda", "apigateway", "dynamodb"],
      "status": "passed",
      "source_info": {
        "source_id": "terraform-registry",
        "source_name": "Terraform Registry",
        "source_type": "template",
        "source_url": "https://registry.terraform.io/modules/terraform-aws-modules/lambda/aws",
        "original_format": "terraform"
      },
      "terraform_code": {
        "main_tf": "# Serverless E-Commerce Order API\n\nresource \"aws_dynamodb_table\" \"orders\" {\n  name           = \"orders\"\n  billing_mode   = \"PAY_PER_REQUEST\"\n  hash_key       = \"order_id\"\n  range_key      = \"customer_id\"\n\n  attribute {\n    name = \"order_id\"\n    type = \"S\"\n  }\n\n  attribute {\n    name = \"customer_id\"\n    type = \"S\"\n  }\n\n  attribute {\n    name = \"status\"\n    type = \"S\"\n  }\n\n  global_secondary_index {\n    name            = \"customer-orders-index\"\n    hash_key        = \"customer_id\"\n    range_key       = \"order_id\"\n    projection_type = \"ALL\"\n  }\n\n  global_secondary_index {\n    name            = \"status-index\"\n    hash_key        = \"status\"\n    projection_type = \"KEYS_ONLY\"\n  }\n\n  tags = {\n    Environment = var.environment\n  }\n}\n\nresource \"aws_dynamodb_table\" \"inventory\" {\n  name           = \"inventory\"\n  billing_mode   = \"PAY_PER_REQUEST\"\n  hash_key       = \"product_id\"\n\n  attribute {\n    name = \"product_id\"\n    type = \"S\"\n  }\n\n  tags = {\n    Environment = var.environment\n  }\n}\n\nresource \"aws_lambda_function\" \"api\" {\n  function_name = \"order-api-handler\"\n  runtime       = \"python3.11\"\n  handler       = \"handlers.lambda_handler\"\n  role          = aws_iam_role.lambda.arn\n  filename      = \"lambda.zip\"\n  timeout       = 30\n  memory_size   = 256\n\n  environment {\n    variables = {\n      ORDERS_TABLE    = aws_dynamodb_table.orders.name\n      INVENTORY_TABLE = aws_dynamodb_table.inventory.name\n      ENVIRONMENT     = var.environment\n    }\n  }\n}\n\nresource \"aws_api_gateway_rest_api\" \"main\" {\n  name = \"order-api\"\n}\n\nresource \"aws_api_gateway_resource\" \"orders\" {\n  rest_api_id = aws_api_gateway_rest_api.main.id\n  parent_id   = aws_api_gateway_rest_api.main.root_resource_id\n  path_part   = \"orders\"\n}\n",
        "variables_tf": "variable \"environment\" {\n  type        = string\n  description = \"Deployment environment\"\n  default     = \"dev\"\n}\n"
      },
      "generated_app": {
        "content_hash": "ecommerce-order-api-v1",
        "source_files": {
          "src/models.py": "\"\"\"Domain models for E-Commerce Order API.\"\"\"\nfrom __future__ import annotations\n\nimport uuid\nfrom dataclasses import dataclass, field\nfrom datetime import datetime\nfrom decimal import Decimal\nfrom enum import Enum\nfrom typing import Optional\n\n\nclass OrderStatus(str, Enum):\n    PENDING = \"pending\"\n    CONFIRMED = \"confirmed\"\n    PROCESSING = \"processing\"\n    SHIPPED = \"shipped\"\n    DELIVERED = \"delivered\"\n    CANCELLED = \"cancelled\"\n\n\nclass PaymentStatus(str, Enum):\n    PENDING = \"pending\"\n    AUTHORIZED = \"authorized\"\n    CAPTURED = \"captured\"\n    FAILED = \"failed\"\n    REFUNDED = \"refunded\"\n\n\n@dataclass\nclass Product:\n    \"\"\"Product in the catalog.\"\"\"\n    product_id: str\n    name: str\n    price: Decimal\n    stock_quantity: int\n    category: str = \"\"\n    is_active: bool = True\n\n\n@dataclass\nclass OrderItem:\n    \"\"\"Line item in an order.\"\"\"\n    product_id: str\n    product_name: str\n    quantity: int\n    unit_price: Decimal\n    \n    @property\n    def subtotal(self) -> Decimal:\n        return self.unit_price * self.quantity\n\n\n@dataclass\nclass ShippingAddress:\n    \"\"\"Customer shipping address.\"\"\"\n    street: str\n    city: str\n    state: str\n    postal_code: str\n    country: str = \"US\"\n\n\n@dataclass\nclass Order:\n    \"\"\"Customer order with line items.\"\"\"\n    order_id: str = field(default_factory=lambda: str(uuid.uuid4()))\n    customer_id: str = \"\"\n    customer_email: str = \"\"\n    items: list[OrderItem] = field(default_factory=list)\n    shipping_address: Optional[ShippingAddress] = None\n    status: OrderStatus = OrderStatus.PENDING\n    payment_status: PaymentStatus = PaymentStatus.PENDING\n    idempotency_key: Optional[str] = None\n    created_at: datetime = field(default_factory=datetime.utcnow)\n    updated_at: datetime = field(default_factory=datetime.utcnow)\n    \n    @property\n    def subtotal(self) -> Decimal:\n        return sum(item.subtotal for item in self.items)\n    \n    @property\n    def tax(self) -> Decimal:\n        return self.subtotal * Decimal(\"0.08\")  # 8% tax\n    \n    @property\n    def total(self) -> Decimal:\n        return self.subtotal + self.tax\n    \n    def to_dynamodb_item(self) -> dict:\n        \"\"\"Convert to DynamoDB item format.\"\"\"\n        return {\n            \"order_id\": {\"S\": self.order_id},\n            \"customer_id\": {\"S\": self.customer_id},\n            \"customer_email\": {\"S\": self.customer_email},\n            \"status\": {\"S\": self.status.value},\n            \"payment_status\": {\"S\": self.payment_status.value},\n            \"subtotal\": {\"N\": str(self.subtotal)},\n            \"tax\": {\"N\": str(self.tax)},\n            \"total\": {\"N\": str(self.total)},\n            \"items\": {\"L\": [\n                {\"M\": {\n                    \"product_id\": {\"S\": item.product_id},\n                    \"product_name\": {\"S\": item.product_name},\n                    \"quantity\": {\"N\": str(item.quantity)},\n                    \"unit_price\": {\"N\": str(item.unit_price)},\n                }} for item in self.items\n            ]},\n            \"created_at\": {\"S\": self.created_at.isoformat()},\n            \"updated_at\": {\"S\": self.updated_at.isoformat()},\n        }\n",
          "src/repositories.py": "\"\"\"Data access layer for DynamoDB operations.\"\"\"\nfrom __future__ import annotations\n\nimport logging\nfrom decimal import Decimal\nfrom typing import Optional\n\nimport boto3\nfrom botocore.exceptions import ClientError\n\nfrom src.config import settings\nfrom src.models import Order, OrderItem, OrderStatus, PaymentStatus\n\nlogger = logging.getLogger(__name__)\n\n\nclass DynamoDBClient:\n    \"\"\"Configured DynamoDB client for LocalStack compatibility.\"\"\"\n    \n    _client = None\n    \n    @classmethod\n    def get_client(cls):\n        if cls._client is None:\n            cls._client = boto3.client(\n                \"dynamodb\",\n                endpoint_url=settings.aws_endpoint_url if settings.use_localstack else None,\n                region_name=settings.aws_region,\n            )\n        return cls._client\n\n\nclass OrderRepository:\n    \"\"\"Repository for order CRUD operations.\"\"\"\n    \n    def __init__(self):\n        self.client = DynamoDBClient.get_client()\n        self.table_name = settings.orders_table\n    \n    def create(self, order: Order) -> Order:\n        \"\"\"Create a new order with idempotency check.\"\"\"\n        try:\n            # Check idempotency\n            if order.idempotency_key:\n                existing = self.get_by_idempotency_key(order.idempotency_key)\n                if existing:\n                    logger.info(\"idempotent_request\", extra={\"order_id\": existing.order_id})\n                    return existing\n            \n            self.client.put_item(\n                TableName=self.table_name,\n                Item=order.to_dynamodb_item(),\n                ConditionExpression=\"attribute_not_exists(order_id)\",\n            )\n            logger.info(\"order_created\", extra={\"order_id\": order.order_id})\n            return order\n        except ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"ConditionalCheckFailedException\":\n                raise DuplicateOrderError(f\"Order {order.order_id} already exists\")\n            raise\n    \n    def get_by_id(self, order_id: str, customer_id: str) -> Optional[Order]:\n        \"\"\"Retrieve order by composite key.\"\"\"\n        response = self.client.get_item(\n            TableName=self.table_name,\n            Key={\n                \"order_id\": {\"S\": order_id},\n                \"customer_id\": {\"S\": customer_id},\n            },\n        )\n        item = response.get(\"Item\")\n        return self._item_to_order(item) if item else None\n    \n    def get_by_customer(self, customer_id: str, limit: int = 20) -> list[Order]:\n        \"\"\"Get all orders for a customer using GSI.\"\"\"\n        response = self.client.query(\n            TableName=self.table_name,\n            IndexName=\"customer-orders-index\",\n            KeyConditionExpression=\"customer_id = :cid\",\n            ExpressionAttributeValues={\":cid\": {\"S\": customer_id}},\n            Limit=limit,\n            ScanIndexForward=False,  # Most recent first\n        )\n        return [self._item_to_order(item) for item in response.get(\"Items\", [])]\n    \n    def update_status(self, order_id: str, customer_id: str, new_status: OrderStatus) -> Order:\n        \"\"\"Update order status with optimistic locking.\"\"\"\n        response = self.client.update_item(\n            TableName=self.table_name,\n            Key={\n                \"order_id\": {\"S\": order_id},\n                \"customer_id\": {\"S\": customer_id},\n            },\n            UpdateExpression=\"SET #status = :status, updated_at = :updated\",\n            ExpressionAttributeNames={\"#status\": \"status\"},\n            ExpressionAttributeValues={\n                \":status\": {\"S\": new_status.value},\n                \":updated\": {\"S\": datetime.utcnow().isoformat()},\n            },\n            ReturnValues=\"ALL_NEW\",\n        )\n        return self._item_to_order(response[\"Attributes\"])\n    \n    def _item_to_order(self, item: dict) -> Order:\n        \"\"\"Convert DynamoDB item to Order model.\"\"\"\n        items = [\n            OrderItem(\n                product_id=i[\"M\"][\"product_id\"][\"S\"],\n                product_name=i[\"M\"][\"product_name\"][\"S\"],\n                quantity=int(i[\"M\"][\"quantity\"][\"N\"]),\n                unit_price=Decimal(i[\"M\"][\"unit_price\"][\"N\"]),\n            )\n            for i in item.get(\"items\", {}).get(\"L\", [])\n        ]\n        \n        return Order(\n            order_id=item[\"order_id\"][\"S\"],\n            customer_id=item[\"customer_id\"][\"S\"],\n            customer_email=item.get(\"customer_email\", {}).get(\"S\", \"\"),\n            items=items,\n            status=OrderStatus(item[\"status\"][\"S\"]),\n            payment_status=PaymentStatus(item.get(\"payment_status\", {}).get(\"S\", \"pending\")),\n        )\n\n\nclass InventoryRepository:\n    \"\"\"Repository for inventory management.\"\"\"\n    \n    def __init__(self):\n        self.client = DynamoDBClient.get_client()\n        self.table_name = settings.inventory_table\n    \n    def reserve_stock(self, product_id: str, quantity: int) -> bool:\n        \"\"\"Atomically reserve stock using conditional update.\"\"\"\n        try:\n            self.client.update_item(\n                TableName=self.table_name,\n                Key={\"product_id\": {\"S\": product_id}},\n                UpdateExpression=\"SET stock_quantity = stock_quantity - :qty\",\n                ConditionExpression=\"stock_quantity >= :qty\",\n                ExpressionAttributeValues={\":qty\": {\"N\": str(quantity)}},\n            )\n            return True\n        except ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"ConditionalCheckFailedException\":\n                return False\n            raise\n    \n    def release_stock(self, product_id: str, quantity: int) -> None:\n        \"\"\"Release reserved stock (e.g., on order cancellation).\"\"\"\n        self.client.update_item(\n            TableName=self.table_name,\n            Key={\"product_id\": {\"S\": product_id}},\n            UpdateExpression=\"SET stock_quantity = stock_quantity + :qty\",\n            ExpressionAttributeValues={\":qty\": {\"N\": str(quantity)}},\n        )\n\n\nclass DuplicateOrderError(Exception):\n    pass\n\n\nclass InsufficientInventoryError(Exception):\n    pass\n",
          "src/services.py": "\"\"\"Business logic for order processing.\"\"\"\nfrom __future__ import annotations\n\nimport logging\nfrom decimal import Decimal\nfrom typing import Optional\n\nfrom src.models import Order, OrderItem, OrderStatus, PaymentStatus\nfrom src.repositories import (\n    OrderRepository,\n    InventoryRepository,\n    InsufficientInventoryError,\n)\n\nlogger = logging.getLogger(__name__)\n\n\nclass OrderService:\n    \"\"\"Handles order creation, processing, and management.\"\"\"\n    \n    def __init__(self):\n        self.order_repo = OrderRepository()\n        self.inventory_repo = InventoryRepository()\n    \n    def create_order(\n        self,\n        customer_id: str,\n        customer_email: str,\n        items: list[dict],\n        idempotency_key: Optional[str] = None,\n    ) -> Order:\n        \"\"\"Create order with inventory reservation (transactional).\"\"\"\n        # Build order items\n        order_items = [\n            OrderItem(\n                product_id=item[\"product_id\"],\n                product_name=item[\"product_name\"],\n                quantity=item[\"quantity\"],\n                unit_price=Decimal(str(item[\"unit_price\"])),\n            )\n            for item in items\n        ]\n        \n        # Validate minimum order\n        order = Order(\n            customer_id=customer_id,\n            customer_email=customer_email,\n            items=order_items,\n            idempotency_key=idempotency_key,\n        )\n        \n        if order.total < Decimal(\"10.00\"):\n            raise MinimumOrderError(\"Minimum order value is $10.00\")\n        \n        # Reserve inventory for each item\n        reserved_items = []\n        try:\n            for item in order_items:\n                if not self.inventory_repo.reserve_stock(item.product_id, item.quantity):\n                    raise InsufficientInventoryError(\n                        f\"Insufficient stock for {item.product_name}\"\n                    )\n                reserved_items.append(item)\n            \n            # Create order\n            order = self.order_repo.create(order)\n            logger.info(\"order_created\", extra={\n                \"order_id\": order.order_id,\n                \"total\": str(order.total),\n                \"items_count\": len(order.items),\n            })\n            return order\n            \n        except Exception:\n            # Rollback inventory reservations\n            for item in reserved_items:\n                self.inventory_repo.release_stock(item.product_id, item.quantity)\n            raise\n    \n    def process_payment(\n        self, order_id: str, customer_id: str, payment_token: str\n    ) -> Order:\n        \"\"\"Process payment for an order.\"\"\"\n        order = self.order_repo.get_by_id(order_id, customer_id)\n        if not order:\n            raise OrderNotFoundError(f\"Order {order_id} not found\")\n        \n        if order.payment_status != PaymentStatus.PENDING:\n            raise InvalidOrderStateError(\n                f\"Cannot process payment for order in {order.payment_status} state\"\n            )\n        \n        # Simulate payment processing\n        # In production: call payment gateway\n        payment_success = self._charge_payment(order.total, payment_token)\n        \n        if payment_success:\n            order = self.order_repo.update_status(order_id, customer_id, OrderStatus.CONFIRMED)\n            logger.info(\"payment_processed\", extra={\"order_id\": order_id})\n        else:\n            order.payment_status = PaymentStatus.FAILED\n            logger.warning(\"payment_failed\", extra={\"order_id\": order_id})\n        \n        return order\n    \n    def cancel_order(self, order_id: str, customer_id: str, reason: str) -> Order:\n        \"\"\"Cancel order and release inventory.\"\"\"\n        order = self.order_repo.get_by_id(order_id, customer_id)\n        if not order:\n            raise OrderNotFoundError(f\"Order {order_id} not found\")\n        \n        if order.status in [OrderStatus.SHIPPED, OrderStatus.DELIVERED]:\n            raise InvalidOrderStateError(\"Cannot cancel shipped/delivered orders\")\n        \n        # Release inventory\n        for item in order.items:\n            self.inventory_repo.release_stock(item.product_id, item.quantity)\n        \n        order = self.order_repo.update_status(order_id, customer_id, OrderStatus.CANCELLED)\n        logger.info(\"order_cancelled\", extra={\"order_id\": order_id, \"reason\": reason})\n        return order\n    \n    def _charge_payment(self, amount: Decimal, token: str) -> bool:\n        \"\"\"Simulate payment gateway call.\"\"\"\n        # In production: integrate with Stripe, PayPal, etc.\n        return token != \"fail\"  # Simulate failure for testing\n\n\nclass OrderNotFoundError(Exception):\n    pass\n\n\nclass InvalidOrderStateError(Exception):\n    pass\n\n\nclass MinimumOrderError(Exception):\n    pass\n",
          "src/handlers.py": "\"\"\"Lambda handlers for API Gateway integration.\"\"\"\nfrom __future__ import annotations\n\nimport json\nimport logging\nimport uuid\nfrom typing import Any\n\nfrom src.services import (\n    OrderService,\n    OrderNotFoundError,\n    InvalidOrderStateError,\n    MinimumOrderError,\n)\nfrom src.repositories import InsufficientInventoryError\n\nlogger = logging.getLogger(__name__)\n\n\ndef lambda_handler(event: dict, context: Any) -> dict:\n    \"\"\"Main Lambda entry point - routes to specific handlers.\"\"\"\n    correlation_id = event.get(\"headers\", {}).get(\n        \"X-Correlation-ID\", str(uuid.uuid4())\n    )\n    \n    logger.info(\"request_received\", extra={\n        \"correlation_id\": correlation_id,\n        \"path\": event.get(\"path\"),\n        \"method\": event.get(\"httpMethod\"),\n    })\n    \n    path = event.get(\"path\", \"\")\n    method = event.get(\"httpMethod\", \"\")\n    \n    try:\n        if path == \"/orders\" and method == \"POST\":\n            return create_order(event)\n        elif path.startswith(\"/orders/\") and method == \"GET\":\n            return get_order(event)\n        elif path.endswith(\"/pay\") and method == \"POST\":\n            return process_payment(event)\n        elif path.endswith(\"/cancel\") and method == \"POST\":\n            return cancel_order(event)\n        else:\n            return api_response(404, {\"error\": \"Not found\"})\n    except Exception as e:\n        logger.exception(\"request_failed\", extra={\"correlation_id\": correlation_id})\n        return api_response(500, {\"error\": \"Internal server error\"})\n\n\ndef create_order(event: dict) -> dict:\n    \"\"\"POST /orders - Create a new order.\"\"\"\n    body = json.loads(event.get(\"body\", \"{}\"))\n    idempotency_key = event.get(\"headers\", {}).get(\"Idempotency-Key\")\n    \n    # Validate required fields\n    required = [\"customer_id\", \"customer_email\", \"items\"]\n    missing = [f for f in required if f not in body]\n    if missing:\n        return api_response(400, {\"error\": f\"Missing fields: {missing}\"})\n    \n    if not body[\"items\"]:\n        return api_response(400, {\"error\": \"Order must contain at least one item\"})\n    \n    try:\n        service = OrderService()\n        order = service.create_order(\n            customer_id=body[\"customer_id\"],\n            customer_email=body[\"customer_email\"],\n            items=body[\"items\"],\n            idempotency_key=idempotency_key,\n        )\n        \n        return api_response(201, {\n            \"order_id\": order.order_id,\n            \"status\": order.status.value,\n            \"subtotal\": str(order.subtotal),\n            \"tax\": str(order.tax),\n            \"total\": str(order.total),\n        })\n    except InsufficientInventoryError as e:\n        return api_response(409, {\"error\": str(e)})\n    except MinimumOrderError as e:\n        return api_response(400, {\"error\": str(e)})\n\n\ndef get_order(event: dict) -> dict:\n    \"\"\"GET /orders/{order_id} - Retrieve order details.\"\"\"\n    order_id = event.get(\"pathParameters\", {}).get(\"order_id\")\n    customer_id = event.get(\"queryStringParameters\", {}).get(\"customer_id\")\n    \n    if not order_id or not customer_id:\n        return api_response(400, {\"error\": \"Missing order_id or customer_id\"})\n    \n    service = OrderService()\n    order = service.order_repo.get_by_id(order_id, customer_id)\n    \n    if not order:\n        return api_response(404, {\"error\": \"Order not found\"})\n    \n    return api_response(200, {\n        \"order_id\": order.order_id,\n        \"customer_id\": order.customer_id,\n        \"status\": order.status.value,\n        \"payment_status\": order.payment_status.value,\n        \"items\": [\n            {\n                \"product_id\": item.product_id,\n                \"product_name\": item.product_name,\n                \"quantity\": item.quantity,\n                \"unit_price\": str(item.unit_price),\n                \"subtotal\": str(item.subtotal),\n            }\n            for item in order.items\n        ],\n        \"subtotal\": str(order.subtotal),\n        \"tax\": str(order.tax),\n        \"total\": str(order.total),\n    })\n\n\ndef process_payment(event: dict) -> dict:\n    \"\"\"POST /orders/{order_id}/pay - Process payment.\"\"\"\n    order_id = event.get(\"pathParameters\", {}).get(\"order_id\")\n    body = json.loads(event.get(\"body\", \"{}\"))\n    \n    try:\n        service = OrderService()\n        order = service.process_payment(\n            order_id=order_id,\n            customer_id=body.get(\"customer_id\"),\n            payment_token=body.get(\"payment_token\"),\n        )\n        return api_response(200, {\n            \"order_id\": order.order_id,\n            \"status\": order.status.value,\n            \"payment_status\": order.payment_status.value,\n        })\n    except OrderNotFoundError:\n        return api_response(404, {\"error\": \"Order not found\"})\n    except InvalidOrderStateError as e:\n        return api_response(409, {\"error\": str(e)})\n\n\ndef cancel_order(event: dict) -> dict:\n    \"\"\"POST /orders/{order_id}/cancel - Cancel order.\"\"\"\n    order_id = event.get(\"pathParameters\", {}).get(\"order_id\")\n    body = json.loads(event.get(\"body\", \"{}\"))\n    \n    try:\n        service = OrderService()\n        order = service.cancel_order(\n            order_id=order_id,\n            customer_id=body.get(\"customer_id\"),\n            reason=body.get(\"reason\", \"Customer requested\"),\n        )\n        return api_response(200, {\n            \"order_id\": order.order_id,\n            \"status\": order.status.value,\n        })\n    except OrderNotFoundError:\n        return api_response(404, {\"error\": \"Order not found\"})\n    except InvalidOrderStateError as e:\n        return api_response(409, {\"error\": str(e)})\n\n\ndef api_response(status_code: int, body: dict) -> dict:\n    return {\n        \"statusCode\": status_code,\n        \"headers\": {\"Content-Type\": \"application/json\"},\n        \"body\": json.dumps(body),\n    }\n"
        },
        "test_files": {
          "tests/test_order_flow.py": "\"\"\"Integration tests for order processing flow.\"\"\"\nimport json\nimport pytest\nfrom decimal import Decimal\n\nfrom src.handlers import lambda_handler\nfrom src.models import OrderStatus\n\n\nclass TestOrderCreation:\n    \"\"\"Test order creation scenarios.\"\"\"\n    \n    def test_create_order_calculates_totals_correctly(self):\n        \"\"\"Order totals should include subtotal + 8% tax.\"\"\"\n        event = {\n            \"path\": \"/orders\",\n            \"httpMethod\": \"POST\",\n            \"headers\": {},\n            \"body\": json.dumps({\n                \"customer_id\": \"cust-123\",\n                \"customer_email\": \"test@example.com\",\n                \"items\": [\n                    {\"product_id\": \"prod-1\", \"product_name\": \"Widget\", \"quantity\": 2, \"unit_price\": 25.00},\n                    {\"product_id\": \"prod-2\", \"product_name\": \"Gadget\", \"quantity\": 1, \"unit_price\": 50.00},\n                ],\n            }),\n        }\n        \n        response = lambda_handler(event, None)\n        body = json.loads(response[\"body\"])\n        \n        assert response[\"statusCode\"] == 201\n        assert Decimal(body[\"subtotal\"]) == Decimal(\"100.00\")\n        assert Decimal(body[\"tax\"]) == Decimal(\"8.00\")\n        assert Decimal(body[\"total\"]) == Decimal(\"108.00\")\n    \n    def test_idempotency_returns_same_order(self):\n        \"\"\"Duplicate requests with same idempotency key return same order.\"\"\"\n        idempotency_key = \"unique-key-12345\"\n        event = {\n            \"path\": \"/orders\",\n            \"httpMethod\": \"POST\",\n            \"headers\": {\"Idempotency-Key\": idempotency_key},\n            \"body\": json.dumps({\n                \"customer_id\": \"cust-123\",\n                \"customer_email\": \"test@example.com\",\n                \"items\": [{\"product_id\": \"prod-1\", \"product_name\": \"Widget\", \"quantity\": 1, \"unit_price\": 20.00}],\n            }),\n        }\n        \n        response1 = lambda_handler(event, None)\n        response2 = lambda_handler(event, None)\n        \n        body1 = json.loads(response1[\"body\"])\n        body2 = json.loads(response2[\"body\"])\n        \n        assert body1[\"order_id\"] == body2[\"order_id\"]\n    \n    def test_insufficient_inventory_returns_409(self):\n        \"\"\"Order with out-of-stock items should fail.\"\"\"\n        event = {\n            \"path\": \"/orders\",\n            \"httpMethod\": \"POST\",\n            \"headers\": {},\n            \"body\": json.dumps({\n                \"customer_id\": \"cust-123\",\n                \"customer_email\": \"test@example.com\",\n                \"items\": [{\"product_id\": \"out-of-stock\", \"product_name\": \"Rare Item\", \"quantity\": 1000, \"unit_price\": 10.00}],\n            }),\n        }\n        \n        response = lambda_handler(event, None)\n        assert response[\"statusCode\"] == 409\n\n\nclass TestPaymentProcessing:\n    \"\"\"Test payment flow.\"\"\"\n    \n    def test_payment_updates_order_status(self, sample_order):\n        \"\"\"Successful payment moves order to CONFIRMED.\"\"\"\n        event = {\n            \"path\": f\"/orders/{sample_order.order_id}/pay\",\n            \"httpMethod\": \"POST\",\n            \"headers\": {},\n            \"pathParameters\": {\"order_id\": sample_order.order_id},\n            \"body\": json.dumps({\n                \"customer_id\": sample_order.customer_id,\n                \"payment_token\": \"valid-token\",\n            }),\n        }\n        \n        response = lambda_handler(event, None)\n        body = json.loads(response[\"body\"])\n        \n        assert response[\"statusCode\"] == 200\n        assert body[\"status\"] == \"confirmed\"\n    \n    def test_failed_payment_keeps_pending(self, sample_order):\n        \"\"\"Failed payment keeps order in PENDING state.\"\"\"\n        event = {\n            \"path\": f\"/orders/{sample_order.order_id}/pay\",\n            \"httpMethod\": \"POST\",\n            \"headers\": {},\n            \"pathParameters\": {\"order_id\": sample_order.order_id},\n            \"body\": json.dumps({\n                \"customer_id\": sample_order.customer_id,\n                \"payment_token\": \"fail\",  # Triggers simulated failure\n            }),\n        }\n        \n        response = lambda_handler(event, None)\n        assert response[\"statusCode\"] == 200\n\n\nclass TestOrderCancellation:\n    \"\"\"Test order cancellation.\"\"\"\n    \n    def test_cancel_releases_inventory(self, sample_order):\n        \"\"\"Cancelling order should release reserved inventory.\"\"\"\n        # Implementation verifies inventory is released\n        pass\n    \n    def test_cannot_cancel_shipped_order(self):\n        \"\"\"Shipped orders cannot be cancelled.\"\"\"\n        # Would need to setup shipped order first\n        pass\n"
        },
        "requirements": ["boto3>=1.28.0", "pydantic>=2.0.0", "pytest>=7.0.0", "moto>=4.0.0"],
        "source_file_count": 4,
        "test_file_count": 1,
        "requirements_count": 4
      }
    },
    {
      "architecture_id": "serverless-rest-api",
      "source_type": "template",
      "services": ["lambda", "s3"],
      "status": "passed",
      "source_info": {
        "source_id": "serverless-examples",
        "source_name": "Serverless Framework Examples",
        "source_type": "template",
        "source_url": "https://github.com/serverless/examples",
        "original_format": "serverless"
      },
      "terraform_code": {
        "main_tf": "# Document Processing Pipeline\n\nresource \"aws_s3_bucket\" \"uploads\" {\n  bucket = \"document-uploads-${var.environment}\"\n}\n\nresource \"aws_s3_bucket\" \"processed\" {\n  bucket = \"document-processed-${var.environment}\"\n}\n\nresource \"aws_lambda_function\" \"processor\" {\n  function_name = \"document-processor\"\n  runtime       = \"python3.11\"\n  handler       = \"handlers.process_document\"\n  role          = aws_iam_role.lambda.arn\n  filename      = \"lambda.zip\"\n  timeout       = 60\n  memory_size   = 512\n}\n\nresource \"aws_s3_bucket_notification\" \"upload_trigger\" {\n  bucket = aws_s3_bucket.uploads.id\n\n  lambda_function {\n    lambda_function_arn = aws_lambda_function.processor.arn\n    events              = [\"s3:ObjectCreated:*\"]\n    filter_prefix       = \"incoming/\"\n  }\n}\n"
      },
      "generated_app": {
        "content_hash": "doc-pipeline-v1",
        "source_files": {
          "src/processor.py": "\"\"\"Document processing pipeline with S3 integration.\"\"\"\nimport hashlib\nimport json\nimport logging\nimport mimetypes\nimport os\nfrom dataclasses import dataclass\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Optional\n\nimport boto3\nfrom botocore.exceptions import ClientError\n\nlogger = logging.getLogger(__name__)\n\n\nclass ProcessingStatus(str, Enum):\n    PENDING = \"pending\"\n    PROCESSING = \"processing\"\n    COMPLETED = \"completed\"\n    FAILED = \"failed\"\n\n\n@dataclass\nclass DocumentMetadata:\n    \"\"\"Extracted document metadata.\"\"\"\n    document_id: str\n    original_filename: str\n    content_type: str\n    size_bytes: int\n    checksum_sha256: str\n    uploaded_at: datetime\n    processed_at: Optional[datetime] = None\n    status: ProcessingStatus = ProcessingStatus.PENDING\n    error_message: Optional[str] = None\n    \n    def to_dict(self) -> dict:\n        return {\n            \"document_id\": self.document_id,\n            \"original_filename\": self.original_filename,\n            \"content_type\": self.content_type,\n            \"size_bytes\": self.size_bytes,\n            \"checksum_sha256\": self.checksum_sha256,\n            \"uploaded_at\": self.uploaded_at.isoformat(),\n            \"processed_at\": self.processed_at.isoformat() if self.processed_at else None,\n            \"status\": self.status.value,\n            \"error_message\": self.error_message,\n        }\n\n\nclass DocumentProcessor:\n    \"\"\"Handles document upload, validation, and processing.\"\"\"\n    \n    MAX_FILE_SIZE = 50 * 1024 * 1024  # 50MB\n    ALLOWED_TYPES = [\"application/pdf\", \"image/png\", \"image/jpeg\", \"text/plain\"]\n    \n    def __init__(self):\n        endpoint_url = os.getenv(\"AWS_ENDPOINT_URL\")\n        self.s3 = boto3.client(\"s3\", endpoint_url=endpoint_url)\n        self.upload_bucket = os.getenv(\"UPLOAD_BUCKET\", \"document-uploads\")\n        self.processed_bucket = os.getenv(\"PROCESSED_BUCKET\", \"document-processed\")\n    \n    def process_upload(self, bucket: str, key: str) -> DocumentMetadata:\n        \"\"\"Process a newly uploaded document.\"\"\"\n        logger.info(\"processing_started\", extra={\"bucket\": bucket, \"key\": key})\n        \n        # Get object metadata\n        try:\n            response = self.s3.head_object(Bucket=bucket, Key=key)\n        except ClientError as e:\n            logger.error(\"object_not_found\", extra={\"error\": str(e)})\n            raise DocumentNotFoundError(f\"Document {key} not found\")\n        \n        size = response[\"ContentLength\"]\n        content_type = response.get(\"ContentType\", \"application/octet-stream\")\n        \n        # Validate file size\n        if size > self.MAX_FILE_SIZE:\n            raise FileTooLargeError(f\"File exceeds {self.MAX_FILE_SIZE} bytes\")\n        \n        # Validate content type\n        if content_type not in self.ALLOWED_TYPES:\n            raise InvalidContentTypeError(f\"Content type {content_type} not allowed\")\n        \n        # Download and compute checksum\n        obj = self.s3.get_object(Bucket=bucket, Key=key)\n        content = obj[\"Body\"].read()\n        checksum = hashlib.sha256(content).hexdigest()\n        \n        # Create metadata\n        document_id = key.split(\"/\")[-1].split(\".\")[0]\n        metadata = DocumentMetadata(\n            document_id=document_id,\n            original_filename=key.split(\"/\")[-1],\n            content_type=content_type,\n            size_bytes=size,\n            checksum_sha256=checksum,\n            uploaded_at=datetime.utcnow(),\n        )\n        \n        # Process based on content type\n        try:\n            processed_key = self._process_content(content, metadata)\n            metadata.status = ProcessingStatus.COMPLETED\n            metadata.processed_at = datetime.utcnow()\n            \n            # Store metadata\n            self._store_metadata(metadata)\n            \n            logger.info(\"processing_completed\", extra={\n                \"document_id\": document_id,\n                \"processed_key\": processed_key,\n            })\n            \n        except Exception as e:\n            metadata.status = ProcessingStatus.FAILED\n            metadata.error_message = str(e)\n            self._store_metadata(metadata)\n            raise\n        \n        return metadata\n    \n    def _process_content(self, content: bytes, metadata: DocumentMetadata) -> str:\n        \"\"\"Process document content based on type.\"\"\"\n        if metadata.content_type == \"application/pdf\":\n            # Extract text from PDF (simulated)\n            processed = self._extract_pdf_text(content)\n        elif metadata.content_type.startswith(\"image/\"):\n            # Generate thumbnail (simulated)\n            processed = self._generate_thumbnail(content)\n        else:\n            # Plain text - just copy\n            processed = content\n        \n        # Upload processed content\n        output_key = f\"processed/{metadata.document_id}/output\"\n        self.s3.put_object(\n            Bucket=self.processed_bucket,\n            Key=output_key,\n            Body=processed,\n            Metadata={\"original_checksum\": metadata.checksum_sha256},\n        )\n        return output_key\n    \n    def _extract_pdf_text(self, content: bytes) -> bytes:\n        \"\"\"Simulate PDF text extraction.\"\"\"\n        # In production: use pdfplumber, PyPDF2, or AWS Textract\n        return b\"Extracted text from PDF document\"\n    \n    def _generate_thumbnail(self, content: bytes) -> bytes:\n        \"\"\"Simulate thumbnail generation.\"\"\"\n        # In production: use Pillow to resize\n        return content[:1000]  # Simulated thumbnail\n    \n    def _store_metadata(self, metadata: DocumentMetadata) -> None:\n        \"\"\"Store document metadata as JSON.\"\"\"\n        self.s3.put_object(\n            Bucket=self.processed_bucket,\n            Key=f\"metadata/{metadata.document_id}.json\",\n            Body=json.dumps(metadata.to_dict()),\n            ContentType=\"application/json\",\n        )\n\n\nclass DocumentNotFoundError(Exception):\n    pass\n\nclass FileTooLargeError(Exception):\n    pass\n\nclass InvalidContentTypeError(Exception):\n    pass\n"
        },
        "test_files": {
          "tests/test_processor.py": "\"\"\"Tests for document processing pipeline.\"\"\"\nimport pytest\nfrom src.processor import DocumentProcessor, FileTooLargeError, InvalidContentTypeError\n\n\nclass TestDocumentValidation:\n    def test_rejects_files_over_50mb(self):\n        \"\"\"Files over 50MB should be rejected.\"\"\"\n        pass\n    \n    def test_rejects_executable_files(self):\n        \"\"\"Executable files should be rejected.\"\"\"\n        pass\n    \n    def test_accepts_valid_pdf(self):\n        \"\"\"Valid PDF files should be processed.\"\"\"\n        pass\n"
        },
        "requirements": ["boto3>=1.28.0", "pytest>=7.0.0"],
        "source_file_count": 1,
        "test_file_count": 1,
        "requirements_count": 2
      }
    },
    {
      "architecture_id": "aws-diagram-microservices",
      "source_type": "diagram",
      "services": ["ecs", "alb", "rds"],
      "status": "partial",
      "error_summary": "ECS task failed to start",
      "test_failures": ["test_ecs_service_running"],
      "source_info": {
        "source_id": "aws-architecture-center",
        "source_name": "AWS Architecture Center",
        "source_type": "diagram",
        "source_url": "https://aws.amazon.com/architecture/",
        "original_format": "diagram",
        "diagram_confidence": 0.85,
        "synthesis_notes": "Inferred ECS cluster from container icons. ALB placement determined from load balancer symbol."
      },
      "terraform_code": {
        "main_tf": "# Microservices Architecture (from diagram)\n\nresource \"aws_ecs_cluster\" \"main\" {\n  name = \"microservices-cluster\"\n\n  setting {\n    name  = \"containerInsights\"\n    value = \"enabled\"\n  }\n}\n\nresource \"aws_ecs_task_definition\" \"api\" {\n  family                   = \"api-service\"\n  network_mode             = \"awsvpc\"\n  requires_compatibilities = [\"FARGATE\"]\n  cpu                      = 256\n  memory                   = 512\n  execution_role_arn       = aws_iam_role.ecs_execution.arn\n\n  container_definitions = jsonencode([{\n    name  = \"api\"\n    image = \"api-service:latest\"\n    portMappings = [{\n      containerPort = 8080\n      protocol      = \"tcp\"\n    }]\n    environment = [\n      { name = \"DB_HOST\", value = aws_db_instance.main.endpoint }\n    ]\n  }])\n}\n\nresource \"aws_lb\" \"api\" {\n  name               = \"api-lb\"\n  internal           = false\n  load_balancer_type = \"application\"\n  subnets            = aws_subnet.public[*].id\n  security_groups    = [aws_security_group.alb.id]\n}\n\nresource \"aws_db_instance\" \"main\" {\n  identifier        = \"microservices-db\"\n  engine            = \"postgres\"\n  engine_version    = \"14\"\n  instance_class    = \"db.t3.micro\"\n  allocated_storage = 20\n  db_name           = \"appdb\"\n  username          = var.db_username\n  password          = var.db_password\n}\n"
      },
      "generated_app": {
        "content_hash": "microservices-v1",
        "source_files": {
          "src/api_service.py": "\"\"\"API Service for Microservices Architecture.\"\"\"\nimport os\nimport uuid\nfrom flask import Flask, jsonify, request\nimport psycopg2\nfrom psycopg2.pool import ThreadedConnectionPool\n\napp = Flask(__name__)\n\n# Database connection pool\ndb_pool = ThreadedConnectionPool(\n    minconn=2,\n    maxconn=10,\n    host=os.getenv(\"DB_HOST\"),\n    database=os.getenv(\"DB_NAME\", \"appdb\"),\n    user=os.getenv(\"DB_USER\"),\n    password=os.getenv(\"DB_PASSWORD\"),\n)\n\n\n@app.route(\"/health\")\ndef health_check():\n    \"\"\"Health check for ALB.\"\"\"\n    try:\n        conn = db_pool.getconn()\n        cursor = conn.cursor()\n        cursor.execute(\"SELECT 1\")\n        db_pool.putconn(conn)\n        return jsonify({\"status\": \"healthy\", \"database\": \"connected\"})\n    except Exception as e:\n        return jsonify({\"status\": \"unhealthy\", \"error\": str(e)}), 503\n\n\n@app.route(\"/api/v1/items\", methods=[\"GET\"])\ndef list_items():\n    \"\"\"List all items with pagination.\"\"\"\n    page = int(request.args.get(\"page\", 1))\n    limit = int(request.args.get(\"limit\", 20))\n    offset = (page - 1) * limit\n    \n    conn = db_pool.getconn()\n    try:\n        cursor = conn.cursor()\n        cursor.execute(\n            \"SELECT id, name, created_at FROM items ORDER BY created_at DESC LIMIT %s OFFSET %s\",\n            (limit, offset)\n        )\n        items = [{\"id\": row[0], \"name\": row[1], \"created_at\": row[2].isoformat()} for row in cursor.fetchall()]\n        return jsonify({\"items\": items, \"page\": page, \"limit\": limit})\n    finally:\n        db_pool.putconn(conn)\n\n\n@app.route(\"/api/v1/items\", methods=[\"POST\"])\ndef create_item():\n    \"\"\"Create a new item.\"\"\"\n    data = request.get_json()\n    item_id = str(uuid.uuid4())\n    \n    conn = db_pool.getconn()\n    try:\n        cursor = conn.cursor()\n        cursor.execute(\n            \"INSERT INTO items (id, name) VALUES (%s, %s) RETURNING created_at\",\n            (item_id, data.get(\"name\"))\n        )\n        created_at = cursor.fetchone()[0]\n        conn.commit()\n        return jsonify({\"id\": item_id, \"name\": data.get(\"name\"), \"created_at\": created_at.isoformat()}), 201\n    finally:\n        db_pool.putconn(conn)\n\n\nif __name__ == \"__main__\":\n    app.run(host=\"0.0.0.0\", port=8080)\n"
        },
        "test_files": {
          "tests/test_api.py": "\"\"\"API service tests.\"\"\"\nimport pytest\n\ndef test_health_check_returns_200():\n    pass\n\ndef test_create_item_persists_to_db():\n    pass\n"
        },
        "requirements": ["flask>=2.0.0", "psycopg2-binary>=2.9.0", "gunicorn>=21.0.0", "pytest>=7.0.0"],
        "source_file_count": 1,
        "test_file_count": 1,
        "requirements_count": 4
      }
    },
    {
      "architecture_id": "aws-solutions-serverless-image",
      "source_type": "template",
      "services": ["lambda", "s3", "rekognition"],
      "status": "failed",
      "error_summary": "Rekognition service not available in LocalStack",
      "infrastructure_error": "Service 'rekognition' is not supported by LocalStack Community Edition",
      "source_info": {
        "source_id": "aws-solutions",
        "source_name": "AWS Solutions Library",
        "source_type": "template",
        "source_url": "https://aws.amazon.com/solutions/",
        "original_format": "cloudformation"
      }
    }
  ],
  "service_coverage": [
    {"name": "lambda", "total": 3, "passed": 2, "failed": 1, "pass_rate": 66.7},
    {"name": "s3", "total": 2, "passed": 2, "failed": 0, "pass_rate": 100.0},
    {"name": "dynamodb", "total": 1, "passed": 1, "failed": 0, "pass_rate": 100.0},
    {"name": "ec2", "total": 1, "passed": 1, "failed": 0, "pass_rate": 100.0},
    {"name": "rds", "total": 2, "passed": 1, "failed": 1, "pass_rate": 50.0}
  ],
  "unsupported_services": ["rekognition"]
}
