{
  "probe_type": "edge_cases",
  "probe_name": "S3/Lambda Edge Cases Probe",
  "probed_features": [
    "concurrent_writes",
    "large_objects",
    "multipart_upload",
    "special_characters"
  ],
  "source_files": {
    "src/probes/s3_edge_cases.py": "\"\"\"S3 Edge Cases Probe.\"\"\"\nfrom __future__ import annotations\n\nimport boto3\nimport os\nfrom dataclasses import dataclass\nfrom typing import Optional\n\n\n@dataclass\nclass ProbeResult:\n    feature: str\n    expected: str\n    actual: str\n    passed: bool\n    error: Optional[str] = None\n\n\nclass S3EdgeCasesProbe:\n    \"\"\"Tests S3 edge cases.\"\"\"\n    \n    def __init__(self):\n        endpoint = os.getenv('AWS_ENDPOINT_URL', 'http://localhost:4566')\n        self.s3 = boto3.client('s3', endpoint_url=endpoint, region_name='us-east-1')\n        self.bucket = 'test-uploads'\n    \n    def test_multipart_upload(self) -> ProbeResult:\n        \"\"\"Test multipart upload workflow.\"\"\"\n        try:\n            key = 'multipart-test.bin'\n            mpu = self.s3.create_multipart_upload(Bucket=self.bucket, Key=key)\n            upload_id = mpu['UploadId']\n            \n            # Upload 2 parts (minimum 5MB each in AWS, LocalStack may differ)\n            parts = []\n            for i in range(1, 3):\n                data = b'X' * (5 * 1024 * 1024)  # 5MB\n                response = self.s3.upload_part(\n                    Bucket=self.bucket, Key=key, UploadId=upload_id,\n                    PartNumber=i, Body=data\n                )\n                parts.append({'PartNumber': i, 'ETag': response['ETag']})\n            \n            self.s3.complete_multipart_upload(\n                Bucket=self.bucket, Key=key, UploadId=upload_id,\n                MultipartUpload={'Parts': parts}\n            )\n            \n            obj = self.s3.head_object(Bucket=self.bucket, Key=key)\n            return ProbeResult(\n                feature='multipart_upload',\n                expected='10MB object',\n                actual=f'{obj[\"ContentLength\"]} bytes',\n                passed=obj['ContentLength'] == 10 * 1024 * 1024,\n            )\n        except Exception as e:\n            return ProbeResult(\n                feature='multipart_upload',\n                expected='Multipart succeeds',\n                actual=str(e),\n                passed=False,\n                error=str(e),\n            )\n    \n    def test_special_characters_in_key(self) -> ProbeResult:\n        \"\"\"Test object keys with special characters.\"\"\"\n        try:\n            special_key = 'test/path with spaces/file (1).txt'\n            self.s3.put_object(Bucket=self.bucket, Key=special_key, Body=b'test')\n            obj = self.s3.get_object(Bucket=self.bucket, Key=special_key)\n            content = obj['Body'].read()\n            return ProbeResult(\n                feature='special_characters',\n                expected='Key preserved',\n                actual=f'Retrieved key with spaces/parens',\n                passed=content == b'test',\n            )\n        except Exception as e:\n            return ProbeResult(\n                feature='special_characters',\n                expected='Special chars work',\n                actual=str(e),\n                passed=False,\n                error=str(e),\n            )\n    \n    def test_unicode_object_key(self) -> ProbeResult:\n        \"\"\"Test object keys with unicode characters.\"\"\"\n        try:\n            unicode_key = 'uploads/文档/résumé.pdf'\n            self.s3.put_object(Bucket=self.bucket, Key=unicode_key, Body=b'pdf content')\n            obj = self.s3.get_object(Bucket=self.bucket, Key=unicode_key)\n            return ProbeResult(\n                feature='unicode_keys',\n                expected='Unicode key preserved',\n                actual='Unicode key works',\n                passed=True,\n            )\n        except Exception as e:\n            return ProbeResult(\n                feature='unicode_keys',\n                expected='Unicode works',\n                actual=str(e),\n                passed=False,\n                error=str(e),\n            )\n    \n    def run_all_probes(self) -> list[ProbeResult]:\n        return [\n            self.test_multipart_upload(),\n            self.test_special_characters_in_key(),\n            self.test_unicode_object_key(),\n        ]\n"
  },
  "test_files": {
    "tests/test_s3_edge_cases.py": "\"\"\"Tests for S3 edge cases.\"\"\"\nimport pytest\nfrom src.probes.s3_edge_cases import S3EdgeCasesProbe\n\n\nclass TestS3EdgeCases:\n    @pytest.fixture\n    def probe(self):\n        return S3EdgeCasesProbe()\n    \n    def test_multipart_upload(self, probe):\n        result = probe.test_multipart_upload()\n        assert result.passed, f\"Multipart upload failed: {result.error}\"\n    \n    def test_special_characters(self, probe):\n        result = probe.test_special_characters_in_key()\n        assert result.passed, f\"Special characters failed: {result.error}\"\n    \n    def test_unicode_keys(self, probe):\n        result = probe.test_unicode_object_key()\n        assert result.passed, f\"Unicode keys failed: {result.error}\"\n"
  },
  "requirements": [
    "boto3>=1.28.0",
    "pytest>=7.0.0"
  ]
}